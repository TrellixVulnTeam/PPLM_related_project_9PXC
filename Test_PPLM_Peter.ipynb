{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test_PPLM_Peter.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oR-elT_D1Wbz","executionInfo":{"status":"ok","timestamp":1654201417460,"user_tz":420,"elapsed":1486,"user":{"displayName":"Yen-ting Huang","userId":"02445510033770410438"}},"outputId":"2e15c550-f969-4823-e892-b053de2d98a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","source":["!pip install transformers==3.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k4ep326o2CXB","executionInfo":{"status":"ok","timestamp":1654201420380,"user_tz":420,"elapsed":2924,"user":{"displayName":"Yen-ting Huang","userId":"02445510033770410438"}},"outputId":"9a166fd6-2b2b-45b8-abcc-ad7ecc3746f7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers==3.0 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0) (21.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0) (0.0.53)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0) (2019.12.20)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3.0) (0.1.96)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0) (3.7.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0) (1.21.6)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0) (0.8.0rc4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0) (2022.5.18.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0) (7.1.2)\n"]}]},{"cell_type":"code","source":["# peter\n","import sys\n","sys.path.append('gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/')\n","!ls 'gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3exJ09hD1Z1v","executionInfo":{"status":"ok","timestamp":1654201422576,"user_tz":420,"elapsed":4,"user":{"displayName":"Yen-ting Huang","userId":"02445510033770410438"}},"outputId":"e415eb16-6961-43d3-85f8-8f64218ad53f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["checkpoint_2epoch.tar.gz\t README.md\n","correct_answered.jsonl\t\t requirements.txt\n","human_annotation\t\t result.json\n","imgs\t\t\t\t run_pplm_discrim_train.py\n","kmir_data_code.tar.gz\t\t run_pplm_old.py\n","LICENSE\t\t\t\t run_pplm.py\n","mnli_classifier_head_epoch_0.pt  shuffle_answer.json\n","mnli_classifier_head_epoch_1.pt  ShuffleGen.ipynb\n","mnli_classifier_head_meta.json\t Test_PPLM.ipynb\n","paper_code\t\t\t Test_PPLM_Peter.ipynb\n","pplm_classification_head.py\t tune_gpt_qa.py\n","__pycache__\t\t\t Untitled.ipynb\n","readme.md\n"]}]},{"cell_type":"code","source":["#peter\n","!rm gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/result.json\n","!touch gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/result.json\n","!python3 gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm_old.py -B science --batch 0 --length 10 --gamma 1.5 --num_iterations 5 --num_samples 3 --stepsize 0.03 --window_length 5 --kl_scale 0.01 --gm_scale 0.99 --colorama --sample --verbosity quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CamLG1g5lyvg","executionInfo":{"status":"ok","timestamp":1654201599644,"user_tz":420,"elapsed":176563,"user":{"displayName":"Yen-ting Huang","userId":"02445510033770410438"}},"outputId":"7b943c5d-9509-4c1b-aa82-e110995a3132"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm_old.py:1024: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_data['correctcontext'] = train_data.apply(lambda row:row['query'].replace(\"[MASK]\", row['oneanswer'].split(\",\")[0]), axis=1)\n","Downloading: 100% 718/718 [00:00<00:00, 676kB/s]\n","Downloading: 100% 1.52G/1.52G [00:37<00:00, 41.0MB/s]\n","Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Downloading: 100% 1.04M/1.04M [00:00<00:00, 2.04MB/s]\n","Downloading: 100% 456k/456k [00:00<00:00, 1.08MB/s]\n","= Prefix of sentence =\n","<|endoftext|>What country is Alberta a part of?\n","\n","= Unperturbed generated text =\n","<|endoftext|>What country is Alberta a part of?\n","\n","Alberta is Canada's northernmost province\n","\n","Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","= Prefix of sentence =\n","<|endoftext|>What region is Turkey a part of?\n","\n","= Unperturbed generated text =\n","<|endoftext|>What region is Turkey a part of? How is Turkey's history? What country are they\n","\n","Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","= Prefix of sentence =\n","<|endoftext|>South Africa is part of what continent?\n","\n","= Unperturbed generated text =\n","<|endoftext|>South Africa is part of what continent? The continent? The continent? What country? And\n","\n","Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","= Prefix of sentence =\n","<|endoftext|>What states does Pennsylvania belong to?\n","\n","= Unperturbed generated text =\n","<|endoftext|>What states does Pennsylvania belong to? How is the state divided? What state does Delaware\n","\n","Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","= Prefix of sentence =\n","<|endoftext|>What is a byte part of?\n","\n","= Unperturbed generated text =\n","<|endoftext|>What is a byte part of? How is a byte part of a byte? A\n","\n","==============================\n","[\n","  {\n","    \"question\": \"<|endoftext|>What country is Alberta a part of?\",\n","    \"bow\": \"Alberta is part of Canada and have Edmonton.\",\n","    \"origin\": \"<|endoftext|>What country is Alberta a part of?\",\n","    \"ours\": [\n","      [\n","        \" Canada Alberta Alberta Alberta Canada Alberta Alberta Alberta Alberta Canada\"\n","      ],\n","      [\n","        \" Alberta is part of Canada.\\n\\nAlberta\"\n","      ],\n","      [\n","        \"\\n\\nAlberta is part of Canada. Alberta\"\n","      ]\n","    ]\n","  },\n","  {\n","    \"question\": \"<|endoftext|>What region is Turkey a part of?\",\n","    \"bow\": \"Turkey is part of Asia Minor and have Euphrates.\",\n","    \"origin\": \"<|endoftext|>What region is Turkey a part of?\",\n","    \"ours\": [\n","      [\n","        \" Turkish is a part of Turkey. Turkey is located\"\n","      ],\n","      [\n","        \" Turkey is part of Turkey. Turkey is not part\"\n","      ],\n","      [\n","        \"\\n\\nTurkey's current border with Turkey is the\"\n","      ]\n","    ]\n","  },\n","  {\n","    \"question\": \"<|endoftext|>South Africa is part of what continent?\",\n","    \"bow\": \"South Africa is part of Africa and have Cape Town.\",\n","    \"origin\": \"<|endoftext|>South Africa is part of what continent?\",\n","    \"ours\": [\n","      [\n","        \" Africa\",\n","        \" South Africa\",\n","        \" South Africa is South Africa\"\n","      ],\n","      [\n","        \" South Africa Is South Africa South Africa is South Africa\"\n","      ],\n","      [\n","        \" Yes South Africa is part of the continent South Africa\"\n","      ]\n","    ]\n","  },\n","  {\n","    \"question\": \"<|endoftext|>What states does Pennsylvania belong to?\",\n","    \"bow\": \"Pennsylvania is part of Mid-Atlantic states and have Allegheny.\",\n","    \"origin\": \"<|endoftext|>What states does Pennsylvania belong to?\",\n","    \"ours\": [\n","      [\n","        \"\\n\\nPennsylvania's state borders the Commonwealth of\"\n","      ],\n","      [\n","        \" Pennsylvania has an electoral vote count of 3, Pennsylvania\"\n","      ],\n","      [\n","        \"\\n\\nPennsylvania is part of the Pennsylvania Federation\"\n","      ]\n","    ]\n","  },\n","  {\n","    \"question\": \"<|endoftext|>What is a byte part of?\",\n","    \"bow\": \"byte is part of word and have bit.\",\n","    \"origin\": \"<|endoftext|>What is a byte part of?\",\n","    \"ours\": [\n","      [\n","        \"\\n\\nA byte part is a part of a\"\n","      ],\n","      [\n","        \"\\n\\nA byte part is a single byte that\"\n","      ],\n","      [\n","        \"\\n\\nWhat's the difference between byte parts,\"\n","      ]\n","    ]\n","  }\n","]\n"]}]},{"cell_type":"code","source":["!python3 gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py -B science --batch 1 --length 10 --gamma 1.5 --num_iterations 5 --num_samples 3 --stepsize 0.03 --window_length 5 --kl_scale 0.01 --gm_scale 0.99 --colorama --sample --verbosity quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k3k4zjfQJ3zY","executionInfo":{"status":"ok","timestamp":1652944403345,"user_tz":420,"elapsed":40282,"user":{"displayName":"Yen-ting Huang","userId":"02445510033770410438"}},"outputId":"5dc00de4-e215-4697-d6e7-d8d00b504485"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py:1024: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_data['correctcontext'] = train_data.apply(lambda row:row['query'].replace(\"[MASK]\", row['oneanswer'].split(\",\")[0]), axis=1)\n","Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","= Prefix of sentence =\n","<|endoftext|>Where was Marshall Jay Williams born?\n","\n","= Unperturbed generated text =\n","<|endoftext|>Where was Marshall Jay Williams born?\n","\n","Marshall J. Williams was born at\n","\n","Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","= Prefix of sentence =\n","<|endoftext|>What country makes HNLMS De Ruyter?\n","\n","Traceback (most recent call last):\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 1030, in <module>\n","    run_pplm_example(**vars(args))\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 867, in run_pplm_example\n","    verbosity_level=verbosity_level\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 558, in full_text_generation\n","    verbosity_level=verbosity_level\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 607, in generate_text_pplm\n","    device)\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 451, in build_bows_one_hot_vectors\n","    single_bow = torch.tensor(single_bow).to(device)\n","ValueError: expected sequence of length 1 at dim 1 (got 0)\n"]}]},{"cell_type":"code","source":["!python3 gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py -B science --batch 2 --length 10 --gamma 1.5 --num_iterations 5 --num_samples 3 --stepsize 0.03 --window_length 5 --kl_scale 0.01 --gm_scale 0.99 --colorama --sample --verbosity quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IPNar98vJ7l2","executionInfo":{"status":"ok","timestamp":1652944424043,"user_tz":420,"elapsed":20717,"user":{"displayName":"Yen-ting Huang","userId":"02445510033770410438"}},"outputId":"7de8ecbd-a360-4c6d-a932-e37b083fb8f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py:1024: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_data['correctcontext'] = train_data.apply(lambda row:row['query'].replace(\"[MASK]\", row['oneanswer'].split(\",\")[0]), axis=1)\n","Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","= Prefix of sentence =\n","<|endoftext|>What country makes ARA Guerrico?\n","\n","Traceback (most recent call last):\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 1030, in <module>\n","    run_pplm_example(**vars(args))\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 867, in run_pplm_example\n","    verbosity_level=verbosity_level\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 558, in full_text_generation\n","    verbosity_level=verbosity_level\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 717, in generate_text_pplm\n","    last = torch.multinomial(pert_probs, num_samples=1)\n","RuntimeError: probability tensor contains either `inf`, `nan` or element < 0\n"]}]},{"cell_type":"code","source":["!python3 gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py -B science --batch 3 --length 10 --gamma 1.5 --num_iterations 5 --num_samples 3 --stepsize 0.03 --window_length 5 --kl_scale 0.01 --gm_scale 0.99 --colorama --sample --verbosity quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XRBAOiPSJ9wM","executionInfo":{"status":"ok","timestamp":1652944463550,"user_tz":420,"elapsed":39516,"user":{"displayName":"Yen-ting Huang","userId":"02445510033770410438"}},"outputId":"f953aac2-02a0-4716-b65a-c2dcf365dedb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py:1024: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_data['correctcontext'] = train_data.apply(lambda row:row['query'].replace(\"[MASK]\", row['oneanswer'].split(\",\")[0]), axis=1)\n","Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","= Prefix of sentence =\n","<|endoftext|>What is Dorothee Wilms nationality?\n","\n","= Unperturbed generated text =\n","<|endoftext|>What is Dorothee Wilms nationality?\n","\n","Dorothee Wilms nationality is\n","\n","Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","= Prefix of sentence =\n","<|endoftext|>What country was the cultural heritage D-2-7237-0082 in?\n","\n","Traceback (most recent call last):\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 1030, in <module>\n","    run_pplm_example(**vars(args))\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 867, in run_pplm_example\n","    verbosity_level=verbosity_level\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 558, in full_text_generation\n","    verbosity_level=verbosity_level\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 607, in generate_text_pplm\n","    device)\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 451, in build_bows_one_hot_vectors\n","    single_bow = torch.tensor(single_bow).to(device)\n","ValueError: expected sequence of length 1 at dim 1 (got 0)\n"]}]},{"cell_type":"code","source":["!python3 gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py -B science --batch 4 --length 10 --gamma 1.5 --num_iterations 5 --num_samples 3 --stepsize 0.03 --window_length 5 --kl_scale 0.01 --gm_scale 0.99 --colorama --sample --verbosity quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0pdHT6wIKANi","executionInfo":{"status":"ok","timestamp":1652944504138,"user_tz":420,"elapsed":40607,"user":{"displayName":"Yen-ting Huang","userId":"02445510033770410438"}},"outputId":"5084c3c0-6ea0-4eb6-fe0d-beda1c970cda"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py:1024: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_data['correctcontext'] = train_data.apply(lambda row:row['query'].replace(\"[MASK]\", row['oneanswer'].split(\",\")[0]), axis=1)\n","Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","= Prefix of sentence =\n","<|endoftext|>What is Johann Ludwig Klüber nationality?\n","\n","= Unperturbed generated text =\n","<|endoftext|>What is Johann Ludwig Klüber nationality?\n","\n","Johann Ludwig Klüber is\n","\n","Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","= Prefix of sentence =\n","<|endoftext|>What country was the cultural heritage D-4-5731-0084 in Coburg?\n","\n","Traceback (most recent call last):\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 1030, in <module>\n","    run_pplm_example(**vars(args))\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 867, in run_pplm_example\n","    verbosity_level=verbosity_level\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 558, in full_text_generation\n","    verbosity_level=verbosity_level\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 607, in generate_text_pplm\n","    device)\n","  File \"gdrive/MyDrive/ucsd/Spring22/Project/PPLM-master/run_pplm.py\", line 451, in build_bows_one_hot_vectors\n","    single_bow = torch.tensor(single_bow).to(device)\n","ValueError: expected sequence of length 1 at dim 1 (got 0)\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","tokenizer_mnli = AutoTokenizer.from_pretrained(\"roberta-large-mnli\") # TODO\n","model_mnli = AutoModelForSequenceClassification.from_pretrained(\"roberta-large-mnli\") # TODO\n","ce_criteria = nn.CrossEntropyLoss()"],"metadata":{"id":"BgIDhomBLcj5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","data = tokenizer_mnli('The capital of France is Paris.', 'The capital of France is the city', truncation=True, return_tensors=\"pt\")\n","data[\"input_ids\"].to(0)\n","data[\"attention_mask\"].to(0)\n","\n","model_mnli.eval()\n","output = model_mnli(data[\"input_ids\"]) \n","target = torch.tensor([[1,0,0]], dtype=torch.float)\n","print(output[0][0], target)\n","print(F.softmax(output[0][0], dim=-1))\n","# print(torch.reshape(F.softmax(output[0][0], dim=-1)[0],(1,1)))\n","ce_criteria(torch.reshape(F.softmax(output[0][0], dim=-1),(1,3)), target)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c7p8Pwt3LctW","executionInfo":{"status":"ok","timestamp":1652912543183,"user_tz":420,"elapsed":749,"user":{"displayName":"zixuan wang","userId":"05594279627921498039"}},"outputId":"31bada9e-7760-47e3-db8f-041e99aea1b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-2.0902,  0.6076,  1.7413], grad_fn=<SelectBackward0>) tensor([[1., 0., 0.]])\n","tensor([0.0161, 0.2396, 0.7443], grad_fn=<SoftmaxBackward0>)\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(1.4636, grad_fn=<DivBackward1>)"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["!python3 /content/gdrive/MyDrive/PPLM-master/run_pplm.py -B science --cond_text \"The capital of France is\" --length 2 --gamma 1.5 --num_iterations 5 --num_samples 1 --stepsize 0.03 --window_length 5 --kl_scale 0.01 --gm_scale 0.99 --colorama --sample"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U50PL3QJ1npd","executionInfo":{"status":"ok","timestamp":1652934755959,"user_tz":420,"elapsed":310,"user":{"displayName":"Yen-ting Huang","userId":"02445510033770410438"}},"outputId":"4f45e805-eb9a-4ac1-d6aa-db26474e1066"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["python3: can't open file '/content/gdrive/MyDrive/PPLM-master/run_pplm.py': [Errno 2] No such file or directory\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"NczfLW_M203c"},"execution_count":null,"outputs":[]}]}